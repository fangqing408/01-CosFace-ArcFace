# 模型训练
## 1 >> 训练

前面已经构建好的所有的部分，现在配置好参数直接开始训练即可。

调用库函数和之前编写的函数。

```python
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
from model import FaceMobileNet
from model.metric import CosFace
from model.loss import FocalLoss
from dataset import load_data
from config import config as conf
```

构建网络、角边距函数、损失函数。

```python
...
if __name__ == '__main__':
    dataloader, class_num = load_data(conf, training=True)
    device = conf.device
    embedding_size = conf.embedding_size
    net = FaceMobileNet(embedding_size).to(device)
    metric = CosFace(embedding_size, class_num).to(device)
    criterion = FocalLoss(gamma=2)
    ...
```

构建优化器，weight_decay 是正则化项的 lambda。

```python
    ...
    optimizer = optim.SGD(
        list(net.parameters()) + list(metric.parameters()),
        lr=conf.lr,
        weight_decay=conf.weight_decay
    )
    ...
```

构建学习率调度器，每隔一个 lr_step，学习率乘以 gamma。

```python
    ...
    scheduler = optim.lr_scheduler.StepLR(
        optimizer, step_size=conf.lr_step, gamma=0.1)
    ...
```

开始训练，记录损失，保存模型。

```python
...
    net.train()
    for e in range(conf.epochs):
        total_loss = 0
        for data, labels in tqdm(dataloader, desc=f"Epoch {e+1}/{conf.epochs}", ascii=True):
            data, labels = data.to(device), labels.to(device)
            optimizer.zero_grad()
            embeddings = net(data)
            thetas = metric(embeddings, labels)
            loss = criterion(thetas, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        avg_loss = total_loss / len(dataloader)
        print(f"Epoch {e+1}/{conf.epochs}, Loss: {avg_loss:.4f}")
        torch.save(net.state_dict(), f"checkpoint_epoch_{e+1}.pth")
        scheduler.step()
```

## 2 >> 构建步骤

- 006 >> [模型测试](https://github.com/fangqing408/01-CosFace-ArcFace/blob/master/recognition/006.md)
