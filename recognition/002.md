# 网络构建

## 1 >> 块的设计

首先，创建一个文件夹叫 model，创建一个空文件 __init__.py，再创建一个文件 fmobilenet.py。

复杂的网络结构可以由一些很简单的块（block）来搭建而成，这里我们先创建一系列的块。

- 001 >> Flatten

第一个块，Flatten，展平一个张量，用于一系列的卷积操作之后，全连接层之前，深度学习模型的卷积操作往往在四维空间，全连接层往往在二维空间，Flatten 能将四位空间展平为二维空间，第一维是批次，后面是这个批次的其他的维度的展平信息。

```python
class Flatten(nn.Module):
    def forward(self, x):
        return x.view(x.shape[0], -1)
```

- 002 >> ConvBn

一个卷积层加上一个标准化层。

nn.Module 是 PyTorch 所有神经网络模块的基类，它内部维护了参数（nn.Parameter）的注册机制和子模块（如 nn.Conv2d、nn.BatchNorm2d）的管理，不使用 super.__init__() 的话会导致子类无法被正确注册，参数不能被识别。

```python
class ConvBn(nn.Module):
    def __init__(self, in_c, out_c, kernel=(1, 1), stride=1, padding=0, groups=1):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_c, out_c, kernel, stride, padding, groups=groups, bias=False),
            nn.BatchNorm2d(out_c)
        )
    def forward(self, x):
        return self.net(x)
```

- 003 >> ConvBnPrelu

第三个块叫 ConvBnPrelu，我们在刚刚搭建好的 ConvBn 块里又加了一个 PReLU 激活层，相较于 ReLU，不直接丢弃负数部分，而是对于负数的数值乘上一个系数。

```python
class ConvBnPrelu(nn.Module):
    def __init__(self, in_c, out_c, kernel=(1, 1), stride=1, padding=0, groups=1):
        super().__init__()
        self.net = nn.Sequential(
            ConvBn(in_c, out_c, kernel, stride, padding, groups),
            nn.PReLU(out_c)
        )
    def forward(self, x):
        return self.net(x)
```

- 004 >> DepthWise

前面两个模块的结合实现了深度可分离卷，大大减少了参数的数量，需要特别注意的是，先转化为 groups 个通道，然后从这个 groups 转化为输出通道，所以 groups 不再受 输入输出通道的限制。

```python
class DepthWise(nn.Module):
    def __init__(self, in_c, out_c, kernel=(3, 3), stride=2, padding=1, groups=1):
        super().__init__()
        self.net = nn.Sequential(
            ConvBnPrelu(in_c, groups, kernel=(1, 1), stride=1, padding=0),
            ConvBnPrelu(groups, groups, kernel=kernel, stride=stride, padding=padding，groups=groups),
            ConvBn(groups, out_c, kernel=(1, 1), stride=1, padding=0),
        )
    def forward(self, x):
        return self.net(x)
```

- 005 >> DepthWiseRes

在上面的基础上添加了输入作为总的前向传播结果，resnet 的精髓。

```python
class DepthWiseRes(nn.Module):
    def __init__(self, in_c, out_c, kernel=(3, 3), stride=2, padding=1, groups=1):
        super().__init__()
        self.net = DepthWise(in_c, out_c, kernel, stride, padding, groups)
    def forward(self, x):
        return self.net(x) + x
```

- 006 >> MultiDepthWiseRes

多传入一个 num_block 的参数，由这个参数决定要堆多少个 DepthWiseRes。由于这些 DepthWiseRes 的输入输出的通道数是一样的，所以堆多少都不会引起通道数的变化。

```python
class MultiDepthWiseRes(nn.Module):
    def __init__(self, num_block, channels, kernel=(3, 3), stride=1, padding=1, groups=1):
        super().__init__()
        self.net = nn.Sequential(*[
            DepthWiseRes(channels, channels, kernel, stride, padding, groups)
            for _ in range(num_block)
        ])
    def forward(self, x):
        return self.net(x)
```

## 2 >> 网络设计

```python
class FaceMobileNet(nn.Module):
    def __init__(self, embedding_size):
        super().__init__()
        self.conv1 = ConvBnPrelu(1, 64, kernel=(3, 3), stride=2, padding=1)
        self.conv2 = ConvBn(64, 64, kernel=(3, 3), stride=1, padding=1, groups=64)
        self.conv3 = DepthWise(64, 64, kernel=(3, 3), stride=2, padding=1, groups=128)
        self.conv4 = MultiDepthWiseRes(num_block=4, channels=64, kernel=3, stride=1, padding=1, groups=128)
        self.conv5 = DepthWise(64, 128, kernel=(3, 3), stride=2, padding=1, groups=256)
        self.conv6 = MultiDepthWiseRes(num_block=6, channels=128, kernel=(3, 3), stride=1, padding=1, groups=256)
        self.conv7 = DepthWise(128, 128, kernel=(3, 3), stride=2, padding=1, groups=512)
        self.conv8 = MultiDepthWiseRes(num_block=2, channels=128, kernel=(3, 3), stride=1, padding=1, groups=256)
        self.conv9 = ConvBnPrelu(128, 512, kernel=(1, 1))
        self.conv10 = ConvBn(512, 512, groups=512, kernel=(7, 7))
        self.flatten = Flatten()
        self.linear = nn.Linear(2048, embedding_size, bias=False)
        self.bn = nn.BatchNorm1d(embedding_size)
    def forward(self, x):
        out = self.conv1(x)
        out = self.conv2(out)
        out = self.conv3(out)
        out = self.conv4(out)
        out = self.conv5(out)
        out = self.conv6(out)
        out = self.conv7(out)
        out = self.conv8(out)
        out = self.conv9(out)
        out = self.conv10(out)
        out = self.flatten(out)
        out = self.linear(out)
        out = self.bn(out)
        return out
```

由于我们的输入是 1 x 128 x 128，经过多层卷积之后，其变成 512 x 2 x 2，也就是 2048，这里的 embedding_size 由外部传入，它表示用多大的向量来表示一张人脸，我们这里使用512。

## 3 >> 测试网络

可能出现维度不匹配的问题，我们在这里对网络的维度输出做一个验证，方便我们发现问题。

```python
if __name__ == "__main__":
    x = Image.open("../samples/009.jpg").convert('L')
    x = x.resize((128, 128))
    x = np.asarray(x, dtype=np.float32)
    x = x[None, None, ...]
    x = torch.from_numpy(x)
    net = FaceMobileNet(512)
    net.eval()
    with torch.no_grad():
        out = net(x)
    print(out.shape)
```

## 4 >> 构建步骤

- 003 >> [损失函数](https://github.com/fangqing408/01-CosFace-ArcFace/blob/master/recognition/003.md)
- 004 >> [角边距函数](https://github.com/fangqing408/01-CosFace-ArcFace/blob/master/recognition/004.md)
- 005 >> [模型训练](https://github.com/fangqing408/01-CosFace-ArcFace/blob/master/recognition/005.md)
- 006 >> [模型测试](https://github.com/fangqing408/01-CosFace-ArcFace/blob/master/recognition/006.md)
