# 模型测试

## 1 >> 测试文件

我们在训练的时候，是训练模型完成正确的分类。在测试阶段，模型将计算两张人脸的相似度。所以我们的测试列表lfw_test_pair.txt是这样子的

```
Abel_Pacheco/Abel_Pacheco_0001.jpg Abel_Pacheco/Abel_Pacheco_0004.jpg 1
Akhmed_Zakayev/Akhmed_Zakayev_0001.jpg Akhmed_Zakayev/Akhmed_Zakayev_0003.jpg 1
... ...
Enrique_Iglesias/Enrique_Iglesias_0001.jpg Gisele_Bundchen/Gisele_Bundchen_0002.jpg 0
Eric_Bana/Eric_Bana_0001.jpg Mike_Sweeney/Mike_Sweeney_0001.jpg 0
```

1表示同一个人，0表示不同。

## 2 >> 图片处理

由于6000个测试用例中，图片是有重复的。我先获取每一个不重复图片的路径。为了不重复，用集合就可以。

```python
def unique_image(pair_list) -> set:
    with open(pair_list, 'r') as fd:
        pairs = fd.readlines()
    unique = set()
    for pair in pairs:
        id1, id2, _ = pair.split()
        unique.add(id1)
        unique.add(id2)
    return unique
```

经过上一步，我们一批一批地计算它们的 embeddings，也称为特征，后文将用特征代表 embeddings。

```python
def group_image(images: set, batch) -> list:
    images = list(images)
    size = len(images)
    res = []
    for i in range(0, size, batch):
        end = min(batch + i, size)
        res.append(images[i : end])
    return res
```

分组好了之后，进行数据预处理。函数名以下划线开头，表示这个函数不希望被用户直接使用。

```python
def _preprocess(images: list, transform) -> torch.Tensor:
    res = []
    for img in images:
        im = Image.open(img)
        im = transform(im)
        res.append(im)
    data = torch.cat(res, dim=0)  # shape: (batch, 128, 128)
    data = data[:, None, :, :]    # shape: (batch, 1, 128, 128)
    return data
```

计算一批图片的特征，并返回一个特征字典。

```python
def featurize(images: list, transform, net, device) -> dict:
    data = _preprocess(images, transform)
    data = data.to(device)
    net = net.to(device)
    with torch.no_grad():
        features = net(data)
    res = {img: feature for (img, feature) in zip(images, features)}
    return res
```

## 3 >> 测试过程

采用余弦距离来度量两张人脸的距离，这跟训练过程是对应的。

```python
def cosin_metric(x1, x2):
    return np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2))
```

选择最佳的阈值即可，比如现在选择阈值为 0.5，即大于 0.5 就认为是一个人，否则认为不是一个人，看看哪个阈值的情况下得到的正确率最高，得到最好的阈值和对应的正确率就是我们的答案。

```python
def threshold_search(y_score, y_true):
    y_score = np.asarray(y_score)
    y_true = np.asarray(y_true)
    best_acc = 0
    best_th = 0
    for i in range(len(y_score)):
        th = y_score[i]
        y_test = (y_score >= th)
        acc = np.mean((y_test == y_true).astype(int))
        if acc > best_acc:
            best_acc = acc
            best_th = th
    return best_acc, best_th
```

```python
def compute_accuracy(feature_dict, pair_list, test_root):
    with open(pair_list, 'r') as f:
        pairs = f.readlines()
    similarities = []
    labels = []
    for pair in pairs:
        img1, img2, label = pair.split()
        img1 = osp.join(test_root, img1)
        img2 = osp.join(test_root, img2)
        feature1 = feature_dict[img1].cpu().numpy()
        feature2 = feature_dict[img2].cpu().numpy()
        label = int(label)
        similarity = cosin_metric(feature1, feature2)
        similarities.append(similarity)
        labels.append(label)
    accuracy, threshold = threshold_search(similarities, labels)
    return accuracy, threshold
```

```python
if __name__ == '__main__':
    model = FaceMobileNet(conf.embedding_size)
    model = nn.DataParallel(model)
    model.load_state_dict(torch.load(conf.test_model, map_location=conf.device))
    model.eval()
    images = unique_image(conf.test_list)
    images = [osp.join(conf.test_root, img) for img in images]
    groups = group_image(images, conf.test_batch_size)
    feature_dict = dict()
    for group in groups:
        d = featurize(group, conf.test_transform, model, conf.device)
        feature_dict.update(d) 
    accuracy, threshold = compute_accuracy(feature_dict, conf.test_list, conf.test_root) 
    print(
        f"Test Model: {conf.test_model}\n"
        f"Accuracy: {accuracy:.3f}\n"
        f"Threshold: {threshold:.3f}\n"
    )
```

## 4 >> 完结撒花 - 20250504 福建厦门
